# from fastapi import APIRouter, HTTPException
# from config.settings import settings
# from routers.schema import (
# StartDialogRequest,
# AskRequest,
# ControlRequest
# )
# from dialog_service.dialog_es import (
#     create_session_es,
#     insert_message_es,
#     get_history_by_session_es,
#     get_session_user_es
# )
# from utils.redis_client import get_redis_client
# from typing import List, Dict, Any
# import httpx
# import json
# from dialog_service.llm_service_new_bak import (StreamDeduper,
#                                                 parse_qwen_stream_chunk_once,
#                                                 call_llm_stream,
#                                                 qwen_stream_raw_events)
# # from dialog_service.llm_service import call_llm
# from fastapi.responses import StreamingResponse
# # from openai import AsyncOpenAI
# import asyncio
#
# router = APIRouter()
#
# # Redis å®¢æˆ·ç«¯
# ioredis = get_redis_client()
#
# # ali_client = AsyncOpenAI(
# #     api_key=settings.deepseek.api_key,
# #     base_url=settings.deepseek.base_url
# # )
#
# @router.post("/dialog/start")
# async def start_dialog(data: StartDialogRequest):
#     talk_id = await create_session_es(int(data.user_id), data.title, data.provider)
#     return {"talk_id": str(talk_id), "provider": data.provider}
#
# @router.post("/dialog/{talk_id}/ask")
# async def ask_question(talk_id: int, data: AskRequest):
#     # âœ… æ£€æŸ¥ talk_id æ˜¯å¦å±äº user_id
#     session_user_id = await get_session_user_es(talk_id)
#     if not session_user_id or str(session_user_id) != data.user_id:
#         raise HTTPException(status_code=403, detail="æ— æƒé™è®¿é—®è¯¥å¯¹è¯")
#
#     # æ ¡éªŒ providerï¼ˆé˜²æ­¢å‰ç«¯ä¼ é”™ï¼‰
#     allowed = {"deepseek", "qwen"}
#     provider = (data.provider or "deepseek").lower()
#     if provider not in allowed:
#         raise HTTPException(status_code=400, detail=f"provider å¿…é¡»æ˜¯ {allowed}")
#
#     # âœ… æŸ¥è¯¢å†å²å¯¹è¯ï¼ˆä¼˜å…ˆ Redisï¼‰
#     # redis_key = f"dialog:history:{data.user_id}:{talk_id}"
#     # history = await ioredis.get(redis_key)
#     # if history and all(is_prompt_format(h) for h in history):
#     #     # ç¼“å­˜æ˜¯æ–°æ ¼å¼ï¼Œç›´æ¥ç”¨
#     #     pass
#     # else:
#     #     history = await get_history_by_session_es(talk_id)
#     #     await ioredis.set(redis_key, str(history), ex=3600)
#
#     redis_key = f"dialog:history:{data.user_id}:{talk_id}"
#     history_raw = await ioredis.get(redis_key)
#     if history_raw:
#         # ioredis é€šå¸¸è¿”å› bytes
#         if isinstance(history_raw, (bytes, bytearray)):
#             history_raw = history_raw.decode("utf-8", errors="ignore")
#         try:
#             history = json.loads(history_raw)
#         except Exception:
#             history = await get_history_by_session_es(talk_id)
#             await ioredis.set(redis_key, json.dumps(history, ensure_ascii=False), ex=3600)
#     else:
#         history = await get_history_by_session_es(talk_id)
#         await ioredis.set(redis_key, json.dumps(history, ensure_ascii=False), ex=3600)
#
#
#
#     # âœ… è°ƒç”¨æ··åˆæ£€ç´¢
#     retrieved = await es_hybrid_search(data.question)
#
#     # âœ… æ„é€  prompt è°ƒç”¨å¤§æ¨¡å‹
#     prompt = build_prompt(history, retrieved, data.question)
#     messages = build_messages(history, retrieved, data.question)
#
#
#
#     async def sse_stream_generator():
#         # èµ·å§‹å¸§
#         yield "event: start\ndata: {}\n\n"
#
#         response_text = ""
#         sent_sources = False
#
#         try:
#             # ====== è°ƒè¯•ï¼šå‘Šè¯‰å‰ç«¯å½“å‰ provider / model ======
#             model_name = getattr(settings.qwen, "model", "qwen-plus") if provider == "qwen" else "<n/a>"
#             yield f"event: debug\ndata: {json.dumps({'provider': provider, 'model': model_name}, ensure_ascii=False)}\n\n"
#
#             if provider == "qwen":
#                 api_key = getattr(settings.qwen, "api_key", "")
#                 model_name = (getattr(data, "model", None) or getattr(settings.qwen, "model", "qwen-plus"))
#                 if not api_key:
#                     yield f"event: error\ndata: {json.dumps({'reason': 'missing_qwen_api_key'}, ensure_ascii=False)}\n\n"
#                     yield "event: end\ndata: {}\n\n"
#                     return
#
#                 # ğŸ‘‡ æ˜¾å¼å¼€å…³ï¼šå‰ç«¯æ²¡ä¼ å°±é»˜è®¤ Falseï¼ˆæé€Ÿï¼‰
#                 enable_search = bool(getattr(data, "enable_search", False))
#
#                 # ğŸ‘‡ æœ€å°å¿…è¦å‚æ•°ï¼ˆéœ€è¦æ¥æºæ—¶å†æŠŠ search_options æ‰“å¼€ï¼‰
#                 qwen_extra = {
#                     "enable_search": enable_search,
#                     "result_format": "message",
#                     "search_options": {
#                         "enable_source": True,  # æƒ³è¦æ¥æºå¿…é¡» True
#                         "citation_format": "[ref_<number>]"
#                         # ä¸å¼ºåˆ¶æœç´¢ï¼Œé¿å…æ— è°“ç­‰å¾…ï¼›ç¡®å®éœ€è¦å¯å†åŠ  "forced_search": True
#                     } if enable_search else None
#                 }
#
#                 # â€”â€” å»é‡å™¨ â€”â€” #
#                 deduper = StreamDeduper(ngram=16, max_count=3)
#
#                 # â€”â€” åŸå§‹äº‹ä»¶æµï¼ˆé¦–å¸§/æ€»æ—¶é™ï¼‰ â€”â€” #
#                 FIRST_FRAME_TIMEOUT = 3.0  # é¦–å¸§æœ€ä¹… 3s
#                 TOTAL_RAW_TIMEOUT = 20.0  # åŸå§‹æµæ€»æ—¶é™ 20s
#
#                 # åˆ›å»ºåŸå§‹äº‹ä»¶ç”Ÿæˆå™¨ï¼ˆæ³¨æ„ï¼šåŒæ—¶ä¼ é¡¶å±‚ kwargsã€extra_bodyã€parametersï¼Œæœ€å¤§å…¼å®¹ï¼‰
#                 raw_iter = qwen_stream_raw_events(
#                     model=model_name,
#                     api_key=api_key,
#                     messages=messages,
#                     extra=qwen_extra  # åœ¨å®ç°é‡Œä¼šåŒæ—¶å¡åˆ° extra_body/parameters
#                 )
#
#                 async def anext_compat(agen):
#                     return await agen.__anext__()
#
#                 start_ts = asyncio.get_event_loop().time()
#
#                 # 1) é¦–å¸§ï¼ˆè¶…æ—¶å…œåº•ï¼‰
#                 try:
#                     raw = await asyncio.wait_for(anext_compat(raw_iter), timeout=FIRST_FRAME_TIMEOUT)
#                 except asyncio.TimeoutError:
#                     # â›‘ é¦–å¸§è¶…æ—¶ï¼šåˆ‡å­—ç¬¦ä¸²æµå…œåº•ï¼ˆé€šå¸¸æ›´å¿«å‡ºå­—ï¼‰
#                     yield f"event: debug\ndata: {json.dumps({'fallback': 'first_frame_timeout->string_stream'}, ensure_ascii=False)}\n\n"
#                     async for chunk in call_llm_stream(
#                             provider="qwen",
#                             messages=messages,
#                             enable_search=enable_search,
#                             qwen_parameters=qwen_extra
#                     ):
#                         if chunk:
#                             response_text += chunk
#                             yield f"data: {chunk}\n\n"
#                     # è·³è¿‡åç»­åŸå§‹æµ
#                     pass
#                 else:
#                     # â€”â€” å¤„ç†é¦–å¸§ â€”â€” #
#                     # è°ƒè¯•ï¼šç¬¬ä¸€å¸§åŸå§‹äº‹ä»¶ï¼ˆå¯ä¿ç•™ 1 å¸§ï¼Œå®šä½å­—æ®µï¼‰
#                     try:
#                         to_dict = getattr(raw, "to_dict", None)
#                         dbg = to_dict() if callable(to_dict) else str(raw)
#                         yield f"event: debug\ndata: {json.dumps({'raw_event': dbg, 'frame': 1}, ensure_ascii=False)}\n\n"
#                     except Exception:
#                         pass
#
#                     text_piece, search_info = parse_qwen_stream_chunk_once(raw)
#
#                     # é¦–æ¬¡æ¥æºï¼ˆåªå‘ä¸€æ¬¡ï¼‰
#                     if (not sent_sources) and search_info:
#                         yield f"event: sources\ndata: {json.dumps(search_info, ensure_ascii=False)}\n\n"
#                         sent_sources = True
#
#                     # æ­£æ–‡
#                     if text_piece:
#                         tail = deduper.feed(text_piece)
#                         if tail:
#                             response_text += tail
#                             yield f"data: {tail}\n\n"
#
#                     # 2) åç»­å¸§ï¼ˆå¸¦æ€»æ—¶é™ï¼‰
#                     frame_idx = 1
#                     while True:
#                         # æ€»æ—¶é™ä¿æŠ¤
#                         if asyncio.get_event_loop().time() - start_ts > TOTAL_RAW_TIMEOUT:
#                             yield f"event: debug\ndata: {json.dumps({'fallback': 'total_raw_timeout->string_stream'}, ensure_ascii=False)}\n\n"
#                             async for chunk in call_llm_stream(
#                                     provider="qwen",
#                                     messages=messages,
#                                     enable_search=enable_search,
#                                     qwen_parameters=qwen_extra
#                             ):
#                                 if chunk:
#                                     response_text += chunk
#                                     yield f"data: {chunk}\n\n"
#                             break
#
#                         try:
#                             raw = await asyncio.wait_for(anext_compat(raw_iter), timeout=5.0)
#                         except (asyncio.TimeoutError, StopAsyncIteration):
#                             break
#
#                         frame_idx += 1
#                         if frame_idx <= 3:  # å†æ‰“ä¸¤å¸§è°ƒè¯•
#                             try:
#                                 to_dict = getattr(raw, "to_dict", None)
#                                 dbg = to_dict() if callable(to_dict) else str(raw)
#                                 yield f"event: debug\ndata: {json.dumps({'raw_event': dbg, 'frame': frame_idx}, ensure_ascii=False)}\n\n"
#                             except Exception:
#                                 pass
#
#                         text_piece, search_info = parse_qwen_stream_chunk_once(raw)
#                         if (not sent_sources) and search_info:
#                             yield f"event: sources\ndata: {json.dumps(search_info, ensure_ascii=False)}\n\n"
#                             sent_sources = True
#                         if text_piece:
#                             tail = deduper.feed(text_piece)
#                             if tail:
#                                 response_text += tail
#                                 yield f"data: {tail}\n\n"
#
#             else:
#                 # DeepSeek ç­‰ï¼šè€çš„å­—ç¬¦ä¸²å¢é‡æµ
#                 async for chunk in call_llm_stream(
#                         provider=provider,
#                         prompt=prompt
#                 ):
#                     response_text += chunk
#                     yield f"data: {chunk}\n\n"
#
#             # ====== æŒä¹…åŒ– & ç¼“å­˜ ======
#             await insert_message_es(talk_id, int(data.user_id), data.question, response_text)
#             history.append({"role": "user", "content": data.question})
#             history.append({"role": "assistant", "content": response_text})
#             await ioredis.set(redis_key, json.dumps(history, ensure_ascii=False), ex=3600)
#
#             # æ•´æ®µä¸ºç©ºï¼Œæ˜ç¡®å‘ŠçŸ¥åŸå› ï¼Œé¿å…åªå‘ end çœ‹ä¸å‡ºé—®é¢˜
#             if not response_text.strip():
#                 yield f"event: error\ndata: {json.dumps({'reason': 'no_text_emitted', 'hint': 'check provider routing / raw event fields / api key'}, ensure_ascii=False)}\n\n"
#
#             yield "event: end\ndata: {}\n\n"
#
#         except Exception as e:
#             err = {"error": str(e)}
#             yield f"event: error\ndata: {json.dumps(err, ensure_ascii=False)}\n\n"
#
#     return StreamingResponse(
#         sse_stream_generator(),
#         media_type="text/event-stream",
#         headers={"Cache-Control": "no-cache", "X-Accel-Buffering": "no"}
#     )
#
#
#
#
# @router.post("/dialog/{talk_id}/control")
# async def control_dialog(talk_id: int, data: ControlRequest):
#     session_user_id = await get_session_user_es(talk_id)
#     if not session_user_id or str(session_user_id) != data.user_id:
#         raise HTTPException(status_code=403, detail="æ— æƒé™è®¿é—®è¯¥å¯¹è¯")
#
#     status_key = f"dialog:status:{data.user_id}:{talk_id}"
#     await ioredis.set(status_key, data.action)
#     return {"status": data.action, "msg": f"å¯¹è¯å·²è®¾ç½®ä¸º {data.action}"}
#
#
#
#
# def build_prompt(history: List[dict], retrieved: List[str], user_input: str):
#     prompt = "ä»¥ä¸‹æ˜¯å†å²å¯¹è¯ï¼Œå¦‚æœä¸é—®é¢˜ä¸ç›¸å…³è¯·å¿½ç•¥ï¼š\n"
#     for h in history[-5:]:
#         role = "ç”¨æˆ·" if h["role"] == "user" else "åŠ©æ‰‹"
#         prompt += f"{role}: {h['content']}\n"
#
#     if retrieved:
#         prompt += "\nä»¥ä¸‹æ˜¯çŸ¥è¯†åº“ä¸­å¯èƒ½ç›¸å…³çš„ä¿¡æ¯ï¼š\n"
#         for i, r in enumerate(retrieved):
#             prompt += f"[ä¿¡æ¯{i+1}] {r}\n"
#
#     prompt += f"\nç”¨æˆ·æé—®: {user_input}\nè¯·åŠ©æ‰‹ç»“åˆå†å²å’ŒçŸ¥è¯†åº“å›ç­”ã€‚"
#     return prompt
#
#
#
#
# async def es_hybrid_search(question: str) -> List[str]:
#     async with httpx.AsyncClient(timeout=10) as client:
#         response = await client.post(
#             "http://localhost:8000/es_hybrid_search",
#             json={"query": question}
#         )
#         response.raise_for_status()
#         return [r["content"] for r in response.json()]
#
# def is_prompt_format(h):
#     return isinstance(h, dict) and "role" in h and "content" in h
#
#
# def build_messages(history: List[Dict[str, Any]], retrieved: List[str], question: str) -> List[Dict[str, str]]:
#     """
#     history: å½¢å¦‚ [{"role":"user","content":"..."},{"role":"assistant","content":"..."}]
#     retrieved: ä½ çš„æ··åˆæ£€ç´¢è¿”å›çš„è‹¥å¹²ç‰‡æ®µ
#     """
#     msgs: List[Dict[str, str]] = []
#
#     # 1) ç³»ç»Ÿæç¤º
#     sys_prompt = (
#         "ä½ æ˜¯ä¸“ä¸šçš„æ£€ç´¢å¢å¼ºé—®ç­”åŠ©æ‰‹ã€‚"
#         "ä¼˜å…ˆåŸºäºã€å€™é€‰èµ„æ–™ã€‘å›ç­”ï¼›è‹¥èµ„æ–™ä¸è¶³ï¼Œå†ç»“åˆå¸¸è¯†ä½œç­”ã€‚"
#         "å¼•ç”¨å¤–éƒ¨æ¥æºæ—¶ä½¿ç”¨è§’æ ‡ [ref_i]ï¼Œä¸æ¥æºåˆ—è¡¨ç¼–å·ä¸€è‡´ï¼›"
#         "è‹¥æ— å¯å¼•ç”¨æ¥æºè¯·å‹¿ç¼–é€ ã€‚"
#     )
#     msgs.append({"role": "system", "content": sys_prompt})
#
#     # 2) æœ€è¿‘å†å²ï¼ˆé˜²è¿‡é•¿ï¼‰
#     for h in (history or [])[-3:]:
#         role = h.get("role")
#         content = h.get("content") or ""
#         if role in ("user", "assistant", "system") and content:
#             msgs.append({"role": role, "content": content})
#
#     # 3) å€™é€‰èµ„æ–™
#     if retrieved:
#         kb = []
#         for i, r in enumerate(retrieved, 1):
#             kb.append(f"[å€™é€‰{i}] {r}")
#         kb_text = "ä»¥ä¸‹ä¸ºå€™é€‰èµ„æ–™ï¼ˆå¯èƒ½éƒ¨åˆ†ä¸ç›¸å…³ï¼Œè¯·è‡ªè¡Œç”„åˆ«ï¼‰ï¼š\n" + "\n".join(kb)
#         msgs.append({"role": "system", "content": kb_text})
#
#     # 4) å½“å‰é—®é¢˜
#     msgs.append({"role": "user", "content": question})
#
#     return msgs





# routers/dialog_routers.py
# æ”¹è¿›ç‚¹ï¼š
# 1) /dialog/start ä¿æŒä¸å˜ï¼ˆåŸºäºä½ ç°æœ‰çš„ ES å­˜å‚¨ï¼‰
# 2) /dialog/{talk_id}/ask æ”¯æŒ stream=true çš„ SSE è¾“å‡ºï¼Œä¸”ä¼šï¼š
#    - å®æ—¶ä¸‹å‘æ­£æ–‡å¢é‡ï¼ˆevent: messageï¼‰
#    - å®æ—¶ä¸‹å‘æ¥æºï¼ˆevent: sourceï¼‰
#    - ç»“æŸæ—¶ä¸‹å‘æ‹¼æ¥åçš„å®Œæ•´æ–‡æœ¬ï¼ˆevent: doneï¼Œå« sources æ±‡æ€»ï¼‰
# 3) éæµå¼æ—¶ï¼Œç›´æ¥è¿”å› {"text": "...", "sources": [...]}
# 4) ç»Ÿä¸€é€šè¿‡ llm_service_new_bak çš„ call_llm_stream / call_llm_onceï¼Œç¡®ä¿æ‹¿åˆ° search_info
import httpx
from fastapi import APIRouter, HTTPException
from fastapi.responses import StreamingResponse
from typing import List, Dict, Any
import json

from routers.schema import (
    StartDialogRequest,
    AskRequest,
    ControlRequest,
)
from dialog_service.dialog_es import (
    create_session_es,
    insert_message_es,           # ç­¾å: (talk_id, user_id, input_content, output_content)
    get_history_by_session_es,
    get_session_user_es,
)
from dialog_service.llm_service_new_bak2 import (
    build_messages,
    call_llm_stream,
)

router = APIRouter()


@router.post("/dialog/start")
async def start_dialog(data: StartDialogRequest):
    """æ–°å»ºå¯¹è¯ï¼Œè¿”å› talk_id"""
    talk_id = await create_session_es(int(data.user_id), data.title or "æ–°ä¼šè¯")
    return {"talk_id": str(talk_id)}


def _sse_pack(event: str, payload: Any) -> str:
    """SSE å¸§ç¼–ç """
    return f"event: {event}\ndata: {json.dumps(payload, ensure_ascii=False)}\n\n"


def _format_sources_block(sources: List[dict]) -> str:
    """æŠŠæ¥æºæ‹¼æ¥æˆå›ç­”æœ«å°¾çš„æ–‡æœ¬å—"""
    if not sources:
        return ""
    lines = []
    for r in sources:
        idx = r.get("index")
        title = (r.get("title") or "").strip()
        url = (r.get("url") or "").strip()
        if idx:
            lines.append(f"[ref_{idx}] {title} {url}".strip())
        else:
            lines.append(f"{title} {url}".strip())
    return "\n\nå‚è€ƒæ¥æºï¼š\n" + "\n".join(lines)


@router.post("/dialog/{talk_id}/ask")
async def ask_dialog(talk_id: int, req: AskRequest):
    """
    æµå¼ SSEï¼š
      - event: message -> æ­£æ–‡å¢é‡ {"delta": "..."}
      - event: source  -> æœ€åä¸€æ¡æ¥æºåˆ—è¡¨ [{"index":..,"title":..,"url":..}, ...]
    ES å…¥åº“ï¼š
      - input_content  = ç”¨æˆ·é—®é¢˜
      - output_content = å®Œæ•´å›ç­” + æ¥æºå—
    """

    # æ ¡éªŒä¼šè¯
    user_id_from_es = await get_session_user_es(talk_id)
    if user_id_from_es is None:
        raise HTTPException(status_code=403, detail="æ— æƒè®¿é—®è¯¥å¯¹è¯ï¼Œæˆ–å¯¹è¯ä¸å­˜åœ¨")

    # å†å²ä¸Šä¸‹æ–‡
    hist = await get_history_by_session_es(talk_id)
    # ğŸ”‘ è°ƒç”¨æ··åˆæ£€ç´¢
    retrieved: List[str] = await es_hybrid_search(req.question)


    # æ„é€  messages
    msgs = build_messages(history=hist, retrieved=retrieved, user_input=req.question)

    provider: str = getattr(req, "provider", None) or "qwen"
    enable_search = True if getattr(req, "enable_search", None) is None else bool(req.enable_search)
    qwen_extra: Dict[str, Any] = getattr(req, "qwen_parameters", None) or {}

    async def gen():
        response_text_parts: List[str] = []
        collected_sources: List[Dict[str, Any]] = []
        seen_urls = set()

        # æ”¶é›†æ¥æºï¼ˆä¸æ¨æµï¼Œæœ€åç»Ÿä¸€å‘ï¼‰
        def on_source_cb(r: Dict[str, Any]):
            url = (r.get("url") or "").strip().lower()
            if url and url not in seen_urls:
                seen_urls.add(url)
                collected_sources.append(r)

        # 1. æµå¼æ¨é€æ­£æ–‡
        async for chunk in call_llm_stream(
            provider=provider,
            messages=msgs,
            enable_search=enable_search,
            qwen_parameters=qwen_extra,
            on_source=on_source_cb,
        ):
            if chunk:
                response_text_parts.append(chunk)
                yield _sse_pack("message", {"delta": chunk})

        # 2. æœ€åä¸€æ¡æ¥æº
        if collected_sources:
            yield _sse_pack("source", collected_sources)

        # 3. å…¥åº“ï¼ˆé—®é¢˜ + å®Œæ•´å›ç­”+æ¥æºï¼‰
        final_text = "".join(response_text_parts).rstrip()
        if collected_sources:
            final_text += _format_sources_block(collected_sources)

        await insert_message_es(
            talk_id,
            int(req.user_id),
            req.question,   # âœ… å­˜åˆ° input_content
            final_text,     # âœ… å­˜åˆ° output_content
        )

    return StreamingResponse(
        gen(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "X-Accel-Buffering": "no",
        },
    )


@router.post("/dialog/{talk_id}/control")
async def control_dialog(talk_id: int, req: ControlRequest):
    """å¯¹è¯æ§åˆ¶å ä½ï¼ˆæŒ‰éœ€å®ç° stop/pause/resume ç­‰ï¼‰"""
    return {"ok": True, "msg": f"received: {getattr(req, 'action', '')}"}


async def es_hybrid_search(question: str) -> List[str]:
    async with httpx.AsyncClient(timeout=10) as client:
        response = await client.post(
            "http://localhost:8000/es_hybrid_search",
            json={"query": question}
        )
        response.raise_for_status()
        return [r["content"] for r in response.json()]