# pdf_ocr/ocr_diag.py
import requests, io, os, sys
import fitz  # PyMuPDF
import numpy as np
from PIL import Image, ImageOps
from paddleocr import PaddleOCR

FILE_URL = "http://localhost:9001/api/v1/download-shared-object/aHR0cDovLzEyNy4wLjAuMTo5MDAwL3dsdy10ZXN0LyVFNSU4OCU5OCVFNCVCQiU5OCVFOCU4MSVBQSVFNSU4RCU5QSVFNSVBMyVBQiVFNiVBRiU5NSVFNCVCOCU5QSVFOCVBRiU4MSVFNiU4OSVBQiVFNiU4RiU4RiVFNCVCQiVCNi5wZGY_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1MWkMxNDBCMVZWTEtWR081RExDMSUyRjIwMjUwOTAxJTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI1MDkwMVQxOTAyMTBaJlgtQW16LUV4cGlyZXM9NDMxOTkmWC1BbXotU2VjdXJpdHktVG9rZW49ZXlKaGJHY2lPaUpJVXpVeE1pSXNJblI1Y0NJNklrcFhWQ0o5LmV5SmhZMk5sYzNOTFpYa2lPaUpNV2tNeE5EQkNNVlpXVEV0V1IwODFSRXhETVNJc0ltVjRjQ0k2TVRjMU5qYzROek16TUN3aWNHRnlaVzUwSWpvaVlXUnRhVzRpZlEuTUF3VDVkdGZsOE04YWZ6WTZwYzFZeE1yWnJJUnNRYmRFYUhUSC13VEMwQ0YyVlFka0kxMnRnN1pvcjlDM1dtcG8tcWxvYTlDQzFwcEZOYzRvQzJmalEmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JnZlcnNpb25JZD1udWxsJlgtQW16LVNpZ25hdHVyZT0zYjNlYThiMDdkOTY3ZmExYzIzMGZmODgwZDU1YzFlYzUzNzI0MGFjN2VhYmM4ZjVhMmFmM2Q1OTAzNzUxODZi"
OUT_DIR = "ocr_diag_out"
os.makedirs(OUT_DIR, exist_ok=True)

def normalize(text: str) -> str:
    import re
    text = text.replace("\u00A0", " ")
    text = re.sub(r"[\t\r]+", " ", text)
    text = re.sub(r"\s+\n", "\n", text)
    text = re.sub(r"\n{3,}", "\n\n", text)
    text = re.sub(r"\s{2,}", " ", text)
    return text.strip()

def flatten(res):
    # å…¼å®¹ä¸åŒè¿”å›ç»“æ„ï¼Œç»Ÿä¸€æŠ½å‡ºæ–‡æœ¬
    texts = []
    if isinstance(res, dict):
        res = res.get("result", res.get("data", res))
    pages = res if isinstance(res, list) else [res]
    for page in pages:
        if isinstance(page, dict):
            page = page.get("data", page.get("result", []))
        if not isinstance(page, list):
            continue
        for line in page:
            # line: [box, (text, score)]
            if isinstance(line, (list, tuple)) and len(line) >= 2:
                val = line[1]
                if isinstance(val, (list, tuple)) and val:
                    txt = val[0]
                    if isinstance(txt, str) and txt.strip():
                        texts.append(txt.strip())
    return texts

def enhance(img: Image.Image) -> Image.Image:
    # ç®€å•å¢å¼ºï¼šè½¬ç°ã€è‡ªåŠ¨å¯¹æ¯”åº¦ã€è½»åº¦é˜ˆå€¼
    gray = ImageOps.grayscale(img)
    gray = ImageOps.autocontrast(gray)
    # è‡ªé€‚åº”é˜ˆå€¼ï¼ˆOtsu çš„è¿‘ä¼¼ç®€åŒ–ï¼‰
    np_img = np.array(gray)
    th = np_img.mean()
    bin_img = (np_img > th).astype(np.uint8) * 255
    return Image.fromarray(bin_img)

def main():
    print("â†’ ä¸‹è½½:", FILE_URL)
    r = requests.get(FILE_URL)
    r.raise_for_status()
    pdf_bytes = r.content
    print(f"âœ… ä¸‹è½½å®Œæˆï¼Œå¤§å°={len(pdf_bytes)/1024:.1f} KB")

    # 1) å…ˆçœ‹æ˜¯å¦æœ¬èº«å°±æœ‰å¯å¤åˆ¶æ–‡æœ¬
    doc = fitz.open(stream=pdf_bytes, filetype="pdf")
    print(f"ğŸ“„ æ€»é¡µæ•°: {doc.page_count}")
    text0 = normalize("".join([(doc.load_page(i).get_text("text") or "") for i in range(doc.page_count)]))
    print(f"ã€PyMuPDF åŸç”Ÿæ–‡æœ¬é¢„è§ˆã€‘:\n{(text0[:400] or 'ï¼ˆç©ºï¼‰')}\n")

    # 2) åˆå§‹åŒ– OCRï¼ˆæ–°ç‰ˆå‚æ•°ï¼Œå‡å°‘å¼ƒç”¨è­¦å‘Šï¼‰
    ocr = PaddleOCR(use_textline_orientation=True, lang="ch")

    DPI = 360   # æé«˜åˆ†è¾¨ç‡
    zoom = DPI / 72.0
    mat = fitz.Matrix(zoom, zoom)

    all_texts = []
    for i in range(doc.page_count):
        page = doc.load_page(i)
        pix = page.get_pixmap(matrix=mat, alpha=False)
        png_path = os.path.join(OUT_DIR, f"page_{i+1}_raw.png")
        with open(png_path, "wb") as f:
            f.write(pix.tobytes("png"))
        print(f"ğŸ–¼ï¸ å·²ä¿å­˜æ¸²æŸ“å›¾: {png_path}  size={pix.width}x{pix.height}")

        img = Image.open(io.BytesIO(pix.tobytes("png"))).convert("RGB")

        # 3) å…ˆè·‘ predict
        try:
            res_pred = ocr.predict(np.array(img))
            texts_pred = flatten(res_pred)
        except Exception as e:
            print(f"[WARN] predict å¼‚å¸¸: {e}")
            texts_pred = []

        # 4) å†è·‘ ocrï¼ˆå…¼å®¹æ—§ç‰ˆï¼‰
        try:
            res_ocr = ocr.ocr(np.array(img))
            texts_ocr = flatten(res_ocr)
        except Exception as e:
            print(f"[WARN] ocr å¼‚å¸¸: {e}")
            texts_ocr = []

        use_texts = texts_pred or texts_ocr
        print(f"Â· ç¬¬ {i+1}/{doc.page_count} é¡µï¼špredictè¡Œæ•°={len(texts_pred)} / ocrè¡Œæ•°={len(texts_ocr)} / é‡‡ç”¨={len(use_texts)}")

        # 5) å¦‚æœä¸¤è€…éƒ½ç©ºï¼Œåšä¸€æ¬¡ç®€å•å¢å¼ºå†è¯•
        if not use_texts:
            enh = enhance(img)
            enh_path = os.path.join(OUT_DIR, f"page_{i+1}_enh.png")
            enh.save(enh_path)
            print(f"ğŸ§ª å¢å¼ºå›¾å·²ä¿å­˜: {enh_path}")
            try:
                res_pred2 = ocr.predict(np.array(enh))
                texts_pred2 = flatten(res_pred2)
            except Exception as e:
                print(f"[WARN] predict(å¢å¼º) å¼‚å¸¸: {e}")
                texts_pred2 = []
            try:
                res_ocr2 = ocr.ocr(np.array(enh))
                texts_ocr2 = flatten(res_ocr2)
            except Exception as e:
                print(f"[WARN] ocr(å¢å¼º) å¼‚å¸¸: {e}")
                texts_ocr2 = []
            use_texts = texts_pred2 or texts_ocr2
            print(f"Â· ç¬¬ {i+1} é¡µå¢å¼ºåï¼špredictè¡Œæ•°={len(texts_pred2)} / ocrè¡Œæ•°={len(texts_ocr2)} / é‡‡ç”¨={len(use_texts)}")

        all_texts.extend(use_texts)
        img.close()

    full_text = normalize("\n".join(all_texts))
    print("\n===== OCR æ–‡æœ¬é¢„è§ˆï¼ˆå‰ 600 å­—ï¼‰=====")
    print(full_text[:600] or "ã€ç©ºã€‘")

    out_txt = os.path.join(OUT_DIR, "full_text.txt")
    with open(out_txt, "w", encoding="utf-8") as f:
        f.write(full_text)
    print(f"\nâœ… ç»“æœå·²ä¿å­˜: {out_txt}")

if __name__ == "__main__":
    sys.exit(main())