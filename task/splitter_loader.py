from langchain_community.document_loaders import (
    PyPDFLoader, UnstructuredWordDocumentLoader, TextLoader,
    UnstructuredMarkdownLoader, CSVLoader, JSONLoader
)
from langchain.text_splitter import (
    CharacterTextSplitter, MarkdownHeaderTextSplitter,
    RecursiveCharacterTextSplitter
)

from pypdf.errors import PdfStreamError
from typing import Callable, Dict
from langchain_core.documents import Document
import pandas as pd
import json
from utils.logger_manager import get_logger  # âœ… å¼•å…¥æ—¥å¿—æ¨¡å—
from utils.task_utils import NonRetryableLoaderError

logger = get_logger("task_file_loader")

# âœ… Excel æ–‡ä»¶å¤„ç†å‡½æ•°ï¼šä¿ç•™ç»“æ„ + æ—¥å¿—
def load_excel_as_text(path: str) -> list:
    try:
        sheets = pd.read_excel(
            path,
            sheet_name=None,
            engine="openpyxl" if path.endswith(".xlsx") else "xlrd"
        )
        docs = []

        for name, df in sheets.items():
            df = df.dropna(how="all", axis=0).dropna(how="all", axis=1)
            if df.empty or df.shape[0] < 3:
                logger.info(f"ğŸ“„ Excel è·³è¿‡ç©º Sheetï¼š{name}")
                continue

            name_lower = name.lower()
            if any(kw in name_lower for kw in ["temp", "è¾…åŠ©", "hidden", "ç¼“å­˜", "ç³»ç»Ÿ"]):
                logger.info(f"ğŸ“„ Excel è·³è¿‡æ— ç”¨ Sheetï¼š{name}")
                continue

            try:
                markdown = df.to_markdown(index=False, tablefmt="grid")
                text = f"ã€Sheet: {name}ã€‘\n{markdown}"
                docs.append(Document(page_content=text))
            except Exception as e:
                logger.warning(f"âš ï¸ Sheet {name} è½¬æ¢å¤±è´¥: {e}")
                docs.append(Document(page_content=f"âš ï¸ Sheet {name} è½¬æ¢å¤±è´¥: {e}"))

        if not docs:
            msg = "âš ï¸ æ‰€æœ‰ Sheet è¢«è·³è¿‡æˆ–æ— æœ‰æ•ˆå†…å®¹"
            logger.warning(f"{path} - {msg}")
            return [Document(page_content=msg)]

        return docs

    except Exception as e:
        logger.exception(f"âŒ Excel è¯»å–å¤±è´¥: {e}")
        return [Document(page_content=f"âŒ Excel è¯»å–å¤±è´¥: {e}")]

# âœ… loader å°è£…å™¨ï¼šç»Ÿä¸€å¼‚å¸¸æ—¥å¿—
def safe_loader(loader_func: Callable[[str], any], path: str, ext: str) -> list:
    # try:
    #     return loader_func(path)
    # except Exception as e:
    #     logger.exception(f"âŒ æ–‡ä»¶åŠ è½½å¤±è´¥: .{ext} - {path} - é”™è¯¯: {e}")
    #     raise RuntimeError(f"æ–‡ä»¶åŠ è½½å¤±è´¥: .{ext} - {e}")
    try:
        return loader_func(path)
    except PdfStreamError as e:
        # æ˜ç¡®è¿™ç±»é”™è¯¯ä¸åº”è§¦å‘ retry
        logger.error(f"âŒ PDF æ–‡ä»¶ç»“æ„æŸåï¼Œä¸é‡è¯•: .{ext} - {path} - é”™è¯¯: {e}")
        raise NonRetryableLoaderError(f"PDF æ–‡ä»¶ç»“æ„æŸå: {e}")
    except Exception as e:
        logger.exception(f"âŒ æ–‡ä»¶åŠ è½½å¤±è´¥: .{ext} - {path} - é”™è¯¯: {e}")
        raise RuntimeError(f"æ–‡ä»¶åŠ è½½å¤±è´¥: .{ext} - {e}")

# âœ… æ–‡ä»¶åŠ è½½å™¨æ˜ å°„ï¼ˆåŠ å…¥å¼‚å¸¸åŒ…è£…ï¼‰
LOADER_MAP: Dict[str, Callable[[str], any]] = {
    "pdf": lambda path: safe_loader(lambda p: PyPDFLoader(p).load(), path, "pdf"),
    "docx": lambda path: safe_loader(lambda p: UnstructuredWordDocumentLoader(p).load(), path, "docx"),
    "txt": lambda path: safe_loader(lambda p: TextLoader(p).load(), path, "txt"),
    "md": lambda path: safe_loader(lambda p: UnstructuredMarkdownLoader(p).load(), path, "md"),
    "csv": lambda path: safe_loader(lambda p: CSVLoader(file_path=p).load(), path, "csv"),
    "xlsx": lambda path: safe_loader(load_excel_as_text, path, "xlsx"),
    "xls": lambda path: safe_loader(load_excel_as_text, path, "xls"),
    "json": lambda path: safe_loader(load_json_with_auto_schema, path, "json"),
}

# âœ… åˆ†å‰²å™¨æ™ºèƒ½æ˜ å°„å‡½æ•°ï¼ˆå¸¦å¼‚å¸¸æ—¥å¿—ï¼‰
def smart_split(ext: str, docs: list):
    try:
        if ext == "md":
            splitter = MarkdownHeaderTextSplitter(headers_to_split_on=[("#", 1), ("##", 2)])
            texts = [doc.page_content for doc in docs]
            chunks = []
            for text in texts:
                chunks.extend(splitter.split_text(text))  # âœ… å‘åå…¼å®¹
            return chunks

        elif ext in ["pdf", "docx", "txt"]:
            splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)
        else:
            splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=50)

        return splitter.split_documents(docs)

    except Exception as e:
        logger.exception(f"âŒ åˆ†æ®µå¤±è´¥ï¼ˆ.{ext} æ–‡æ¡£ï¼‰ï¼Œé”™è¯¯: {e}")
        return [Document(page_content=f"âŒ åˆ†æ®µå¤±è´¥: {e}")]

# âœ… åˆ†å‰²å™¨æ³¨å†Œè¡¨
SPLITTER_MAP: Dict[str, Callable[[list], list]] = {
    ext: (lambda docs, ext=ext: smart_split(ext, docs))
    for ext in LOADER_MAP.keys()
}



def load_json_with_auto_schema(path: str):
    # å…ˆè¯»å–åŸå§‹å†…å®¹ï¼Œåˆ¤æ–­ç»“æ„
    with open(path, 'r', encoding='utf-8') as f:
        content = json.load(f)

    # åŠ¨æ€é€‰æ‹© jq_schema
    if isinstance(content, list):
        # æ˜¯æ•°ç»„ï¼Œå°è¯•æå– content å­—æ®µ
        jq_schema = ".[] | .content"
    elif isinstance(content, dict):
        # æ˜¯å¯¹è±¡ï¼Œç›´æ¥æå– content
        jq_schema = ".content"
    else:
        # æ˜¯å­—ç¬¦ä¸²æˆ–å…¶ä»–ï¼Œç›´æ¥è¿”å›åŸæ–‡
        jq_schema = "."

    # ä½¿ç”¨åŠ¨æ€ schema åŠ è½½æ–‡æ¡£
    return JSONLoader(file_path=path, jq_schema=jq_schema).load()